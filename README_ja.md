# Firecrawl with SearXNGçµ±åˆç’°å¢ƒ (æ—¥æœ¬èªç‰ˆ)

SearXNGã‚’æ¤œç´¢ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹Firecrawlã®ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆç‰ˆã§ã™ã€‚æ—¥æœ¬èªæ¤œç´¢ã¨æ·±åº¦ãƒªã‚µãƒ¼ãƒã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### å‰ææ¡ä»¶
- DockeråŠã³Docker ComposeãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨
- 8GBä»¥ä¸Šã®RAMæ¨å¥¨ï¼ˆPlaywright Chromiumãƒ“ãƒ«ãƒ‰ã®ãŸã‚ï¼‰

### 1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
```bash
git clone git@github.com:Ozamatash/localfirecrawl.git
cd localfirecrawl
```

### 2. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
`.env.example`ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦`.env`ã‚’ä½œæˆã—ã€ä»¥ä¸‹ã®å€¤ã‚’è¨­å®šï¼š

```bash
# LMStudio APIè¨­å®šï¼ˆæ¨å¥¨ï¼‰
OPENAI_API_BASE=http://133.53.17.85:1234/v1
OPENAI_API_KEY=lm-studio
OPENAI_MODEL_NAME=glm-4.5-air #Think modelã§ã™

# SearXNGã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰
SEARXNG_SECRET_KEY=ç”Ÿæˆã•ã‚ŒãŸã‚­ãƒ¼

# ãƒãƒ¼ãƒˆè¨­å®š
PORT=3002
```

**SearXNGã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼ã®ç”Ÿæˆï¼š**
```bash
# Node.jsä½¿ç”¨
node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"

# ã¾ãŸã¯OpenSSLä½¿ç”¨
openssl rand -hex 32
```

### 3. SearXNGè¨­å®šã®æœ€é©åŒ–ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
[`settings.yml`](settings.yml)ã§ä»¥ä¸‹ã®é‡è¦è¨­å®šã‚’ç¢ºèªï¼š

```yaml
general:
  default_lang: "ja"  # æ—¥æœ¬èªã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
  
ui:
  default_locale: "ja"
  
search:
  languages: ["ja", "ja-JP", "en-US", "en", "auto"]
  
engines:
  # æ—¥æœ¬èªæ¤œç´¢ã«å¼·ã„Bingã‚¨ãƒ³ã‚¸ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
  - name: bing
    engine: bing
    categories: general
```

### 4. ãƒãƒ¼ãƒˆè¨­å®šã®å¤‰æ›´
[`docker-compose.yml`](docker-compose.yml)ã§ä»¥ä¸‹ã®ãƒãƒ¼ãƒˆè¨­å®šã‚’ç¢ºèªï¼š

```yaml
searxng:
  ports:
    - "8088:8080"  # SearXNG Web UI

api:
  ports:
    - "3100:3002"  # Firecrawl API

playwright-service:
  ports:
    - "3111:3000"  # Playwright Service
```

### 5. ç’°å¢ƒã®æ§‹ç¯‰ã¨èµ·å‹•
```bash
# Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ“ãƒ«ãƒ‰ï¼ˆåˆå›ç´„13-15åˆ†ï¼‰
docker-compose build

# ã‚µãƒ¼ãƒ“ã‚¹ã®èµ·å‹•
docker-compose up -d

# ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã®ç¢ºèª
docker-compose ps
```

## ğŸŒ ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

### ä¸»è¦ã‚µãƒ¼ãƒ“ã‚¹
- **SearXNG Web UI**: http://localhost:8088
- **SearXNG API**: http://localhost:8088/search
- **Firecrawl API**: http://localhost:3100
- **Playwright Service**: http://localhost:3111

### å‹•ä½œç¢ºèª
```bash
# SearXNGæ¤œç´¢ãƒ†ã‚¹ãƒˆ
curl "http://localhost:8088/search?q=test&format=json"

# Firecrawl APIãƒ†ã‚¹ãƒˆ
curl -X POST "http://localhost:3100/v0/scrape" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'

# Playwrightã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ
curl "http://localhost:3111/health"
```

## ğŸ” æ—¥æœ¬èªæ¤œç´¢ã®ä½¿ç”¨æ–¹æ³•

### Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä½¿ç”¨
1. ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:8088 ã«ã‚¢ã‚¯ã‚»ã‚¹
2. æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹ã«æ—¥æœ¬èªã‚’ç›´æ¥å…¥åŠ›ï¼ˆä¾‹ï¼šã€Œäººå·¥çŸ¥èƒ½ã€ï¼‰
3. å¤šæ§˜ãªæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰çµ±åˆçµæœã‚’å–å¾—

### APIçµŒç”±ã§ã®æ—¥æœ¬èªæ¤œç´¢
æ—¥æœ¬èªã‚¯ã‚¨ãƒªã«ã¯URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™ï¼š

```bash
# æ—¥æœ¬èªæ¤œç´¢ä¾‹ï¼šã€Œåªç”°é™½ä¸€ã€
# URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰: %E5%9D%AA%E7%94%B0%E9%99%BD%E4%B8%80
curl "http://localhost:8088/search?q=%E5%9D%AA%E7%94%B0%E9%99%BD%E4%B8%80&format=json"

# Pythonä½¿ç”¨ä¾‹
import urllib.parse
import requests

query = "åªç”°é™½ä¸€"
encoded_query = urllib.parse.quote(query)
response = requests.get(f"http://localhost:8088/search?q={encoded_query}&format=json")
```

## ğŸ› ï¸ Deep Researchè¨­å®šæ–¹æ³•

### 1. æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®æ‹¡å¼µè¨­å®š
`settings.yml`ã§å­¦è¡“ãƒ»å°‚é–€æ¤œç´¢ã‚’å¼·åŒ–ï¼š

```yaml
engines:
  # å­¦è¡“æ¤œç´¢
  - name: google_scholar
    engine: google_scholar
    categories: science
    
  - name: arxiv
    engine: arxiv
    categories: science
    
  - name: wikipedia_ja
    engine: wikipedia
    base_url: 'https://ja.wikipedia.org/'
    categories: general
    
  # é–‹ç™ºè€…ãƒªã‚µãƒ¼ãƒ
  - name: github
    engine: github
    categories: it
```

### 2. ã‚«ãƒ†ã‚´ãƒªåˆ¥æ¤œç´¢ã®æ´»ç”¨
```bash
# å­¦è¡“è«–æ–‡æ¤œç´¢
curl "http://localhost:8088/search?q=machine+learning&categories=science&format=json"

# ITæŠ€è¡“æ¤œç´¢
curl "http://localhost:8088/search?q=docker&categories=it&format=json"

# ç·åˆæ¤œç´¢
curl "http://localhost:8088/search?q=ç ”ç©¶&categories=general&format=json"
```

### 3. Firecrawlçµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
æ¤œç´¢â†’è©³ç´°åˆ†æã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼š

```bash
# ã‚¹ãƒ†ãƒƒãƒ—1: é–¢é€£æƒ…å ±ã‚’æ¤œç´¢
curl "http://localhost:8088/search?q=%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD&format=json" \
  | jq '.results[].url' > urls.txt

# ã‚¹ãƒ†ãƒƒãƒ—2: è¦‹ã¤ã‹ã£ãŸURLã‚’è©³ç´°ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
curl -X POST "http://localhost:3100/v0/scrape" \
  -H "Content-Type: application/json" \
  -d '{"url": "è¦‹ã¤ã‹ã£ãŸURL", "formats": ["markdown", "html"]}'
```

## âš™ï¸ é«˜åº¦ãªè¨­å®š

### LMStudioçµ±åˆ
LLMæ”¯æ´æ©Ÿèƒ½ã®ãŸã‚ã®è¨­å®šï¼š

```bash
# .envãƒ•ã‚¡ã‚¤ãƒ«
OPENAI_API_BASE=http://133.53.17.85:1234/v1
OPENAI_API_KEY=lm-studio
OPENAI_MODEL_NAME=glm-4-5-air(Think modelã§ã™)

# APIãƒ†ã‚¹ãƒˆ
curl -X POST "http://localhost:3100/v0/scrape" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com", "formats": ["llm-extraction"]}'
```

### ãƒ—ãƒ­ã‚­ã‚·ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
`settings.yml`ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã®èª¿æ•´ï¼š

```yaml
server:
  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼
  secret_key: "your-secret-key"
  
outgoing:
  # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
  proxies:
    http: "http://proxy:8080"
    https: "https://proxy:8080"
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
```yaml
# æ¤œç´¢çµæœæ•°ã®èª¿æ•´
search:
  default_http_headers:
    User-Agent: "SearXNG/1.0"
  
# ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
engines:
  - name: google
    timeout: 10.0
    
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
redis:
  url: redis://redis:6379/0
```

## ğŸ§ª å®Ÿéš›ã®ç ”ç©¶ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¾‹

### ä¾‹1: ç ”ç©¶è€…æƒ…å ±ã®æ·±åº¦èª¿æŸ»
```bash
# 1. ç ”ç©¶è€…åã§æ¤œç´¢
RESEARCHER="åªç”°é™½ä¸€"
ENCODED=$(python3 -c "import urllib.parse; print(urllib.parse.quote('$RESEARCHER'))")
curl "http://localhost:8088/search?q=$ENCODED&format=json" > search_results.json

# 2. ç ”ç©¶æ©Ÿé–¢ãƒšãƒ¼ã‚¸ã‚’ç‰¹å®šãƒ»æŠ½å‡º
jq -r '.results[] | select(.url | contains("researchmap")) | .url' search_results.json | head -1 > target_url.txt

# 3. è©³ç´°æƒ…å ±ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
curl -X POST "http://localhost:3100/v0/scrape" \
  -H "Content-Type: application/json" \
  -d "{\"url\": \"$(cat target_url.txt)\"}" > researcher_data.json

# 4. è«–æ–‡ãƒªã‚¹ãƒˆã‚‚å–å¾—
jq -r '.results[] | select(.url | contains("scholar")) | .url' search_results.json | head -5 | \
while read url; do
  curl -X POST "http://localhost:3100/v0/scrape" \
    -H "Content-Type: application/json" \
    -d "{\"url\": \"$url\"}" >> papers_data.json
done
```

### ä¾‹2: æŠ€è¡“å‹•å‘èª¿æŸ»
```bash
# æœ€æ–°ã®AIæŠ€è¡“å‹•å‘ã‚’èª¿æŸ»
curl "http://localhost:8088/search?q=GPT-4&categories=science,it&format=json" | \
jq '.results[] | select(.score > 0.8) | {title, url, snippet}' > ai_trends.json

# é‡è¦ãªãƒšãƒ¼ã‚¸ã‚’è©³ç´°åˆ†æ
jq -r '.url' ai_trends.json | head -10 | \
while read url; do
  curl -X POST "http://localhost:3100/v0/scrape" \
    -H "Content-Type: application/json" \
    -d "{\"url\": \"$url\", \"formats\": [\"markdown\"]}" \
    >> tech_analysis.json
done
```

## ğŸ“Š ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

### ãƒ­ã‚°ç¢ºèª
```bash
# å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ­ã‚°
docker-compose logs

# ç‰¹å®šã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ­ã‚°
docker-compose logs searxng
docker-compose logs api
docker-compose logs playwright-service

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°
docker-compose logs -f searxng
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
```bash
# ã‚³ãƒ³ãƒ†ãƒŠãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
docker stats

# ã‚µãƒ¼ãƒ“ã‚¹å¿œç­”æ™‚é–“æ¸¬å®š
time curl "http://localhost:8088/search?q=test&format=json" > /dev/null
time curl -X POST "http://localhost:3100/v0/scrape" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}' > /dev/null
```

### è¨­å®šå¤‰æ›´ã®é©ç”¨
```bash
# SearXNGè¨­å®šå¤‰æ›´å¾Œ
docker-compose restart searxng

# ç’°å¢ƒå¤‰æ•°å¤‰æ›´å¾Œ
docker-compose down
docker-compose up -d

# å®Œå…¨ãªå†ãƒ“ãƒ«ãƒ‰
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

#### 1. SearXNG Forbiddenã‚¨ãƒ©ãƒ¼
```bash
# è¨€èªè¨­å®šã‚’ç¢ºèª
grep -A 5 "default_lang" settings.yml

# ä¿®æ­£æ–¹æ³•: settings.ymlã§
# default_lang: "ja"
# languages: ["ja", "ja-JP", "en-US", "en", "auto"]
```

#### 2. æ—¥æœ¬èªæ¤œç´¢ã§çµæœãŒå‡ºãªã„
```bash
# URLã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèª
python3 -c "import urllib.parse; print(urllib.parse.quote('æ¤œç´¢èª'))"

# Bingã‚¨ãƒ³ã‚¸ãƒ³ãŒæœ‰åŠ¹ã‹ç¢ºèª
grep -A 10 "name: bing" settings.yml
```

#### 3. Firecrawl APIãŒå¿œç­”ã—ãªã„
```bash
# ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
docker-compose ps api

# ãƒ­ã‚°ç¢ºèª
docker-compose logs api

# å†èµ·å‹•
docker-compose restart api
```

#### 4. ãƒ¡ãƒ¢ãƒªä¸è¶³
```bash
# ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
docker stats --no-stream

# ä¸è¦ãªã‚³ãƒ³ãƒ†ãƒŠå‰Šé™¤
docker system prune

# ã‚¹ãƒ¯ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆLinuxï¼‰
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

## ğŸ“š API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### SearXNG API
```bash
# åŸºæœ¬æ¤œç´¢
GET /search?q={query}&format=json

# ã‚«ãƒ†ã‚´ãƒªæŒ‡å®šæ¤œç´¢
GET /search?q={query}&categories=science&format=json

# è¨€èªæŒ‡å®šæ¤œç´¢
GET /search?q={query}&lang=ja&format=json

# ã‚¨ãƒ³ã‚¸ãƒ³æŒ‡å®šæ¤œç´¢
GET /search?q={query}&engines=google,bing&format=json
```

### Firecrawl API
```bash
# åŸºæœ¬ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
POST /v0/scrape
{
  "url": "https://example.com"
}

# ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæŒ‡å®š
POST /v0/scrape
{
  "url": "https://example.com",
  "formats": ["markdown", "html", "structured"]
}

# ãƒãƒƒãƒã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
POST /v0/batch-scrape
{
  "urls": ["https://example1.com", "https://example2.com"],
  "formats": ["markdown"]
}
```

## ğŸ¤ è²¢çŒ®ã¨ã‚µãƒãƒ¼ãƒˆ

### ãƒã‚°å ±å‘Š
å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®æƒ…å ±ã¨å…±ã«Issueã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
- OSæƒ…å ±ã¨Dockerãƒãƒ¼ã‚¸ãƒ§ãƒ³
- ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ï¼ˆ`docker-compose logs`ã®å‡ºåŠ›ï¼‰
- å†ç¾æ‰‹é †

### æ©Ÿèƒ½æ”¹å–„
- æ–°ã—ã„æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®è¿½åŠ 
- å¤šè¨€èªå¯¾å¿œã®æ”¹å–„
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

---

**ã“ã®READMEã¯æ—¥æœ¬èªç’°å¢ƒã§ã®ä½¿ç”¨ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚è‹±èªç‰ˆã¯[README.md](README.md)ã‚’ã”è¦§ãã ã•ã„ã€‚**